{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dlt (Deep Learning Tools) パッケージの使い方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この記事は、[Kerasを用いたCIFAR-10チュートリアル](https://qiita.com/hiroyuki827/items/8c59cb26844b6db46f06)で用いるdltパッケージの使い方をまとめたものです。\n",
    "\n",
    "English version is [HERE](../dltパッケージの使い方/How_to_use_dlt_package/How_to_use_dlt_package.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 誰が作ったか?\n",
    "\n",
    "もともとこのパッケージを作ったのは、RWTH Aachen工科大学の[David Waltz](https://github.com/DavidWalz/dlipr)氏です。私は彼の「Deep Learning in Physics Research」という講義を取っており、その講義を通してDeep Learningを学びました。この講義で使われていたdltは、大学のクラスター上で動くものでしたが、私は個人のコンピュータでも動くように修正し、`dlt` (Deep Learning Tools)として、ここで公開することにしました。\n",
    "\n",
    "#### このノートについて\n",
    "\n",
    "\n",
    "\n",
    "この記事では、それらをどう使うかを紹介していきます。以下では、**[Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist/blob/master/README.ja.md)** を例に扱ってみます。ここでは詳しいディープラーニングの内容は解説しませんが、dltを使えばどんな結果を得ることができるかを知っていただくことを目的としているので、ディープラーニングについて知らなくても構いません。少々理解できないところがあっても、後から理解されることをおすすめします。\n",
    "\n",
    "- `dlt`を使うところでは、★マークを使っています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## どう使えばよいか?\n",
    "\n",
    "### 準備\n",
    "\n",
    "まず、ライブラリのバージョンを示しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.4.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dltパッケージを使うために、\n",
    "\n",
    "```\n",
    "pip install dlt\n",
    "```\n",
    "を実行してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ディープラーニング - Fashion-MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本的には[MNISTのサンプルコード](https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py)を参考にします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import os \n",
    "import numpy as np\n",
    "import dlt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ★ データセットの読み込み\n",
    "\n",
    "Fashion MNISTのデータセットを読み込むメソッドは以下のようにして読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Fashion-MNIST dataset\n"
     ]
    }
   ],
   "source": [
    "data = dlt.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dltでは以下のデータセットを用意しています: `CIFAR-10`, `CIFAR-100`, `MNIST`, `FASHION-MNIST`\n",
    "- 各ファイルに上記の`load_data`に相当するメソッドが定義されています。\n",
    "\n",
    "各データには以下のようにアクセスできます。Fashion MNISTはMNISTと同じデータ量（フォーマット）で提供されているので、MNISTと同じように扱えます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 訓練データ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.train_images\n",
    "y_train = data.train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### テストデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = data.test_images\n",
    "y_test = data.test_labels\n",
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "★また、各ターゲットとなるデータセット`y_train`, `y_test`に、正解ラベルがどういう分布で含まれているかは以下のようにしてチェックできます。代表的なデータセットはラベルの偏りがないように、それぞれのラベルに対して同数の学習データが用意されています。自分で画像を持ってきて用意する際も、なるべくこのようにすることが理想的です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Value: 6000\n",
      "Median Value: 6000.0\n",
      "Variance: 0\n",
      "Standard Deviation: 0.0\n"
     ]
    }
   ],
   "source": [
    "dlt.utils.plot_distribution_data(Y=data.train_labels, #正解ラベルのデータセット\n",
    "                                 dataset_name='y_train', # そのデータセットの名前\n",
    "                                 classes=data.classes, # ラベル\n",
    "                                 fname='dist_train.png' # 出力するファイルパス\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"dist_train.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Value: 6000\n",
      "Median Value: 6000.0\n",
      "Variance: 0\n",
      "Standard Deviation: 0.0\n"
     ]
    }
   ],
   "source": [
    "dlt.utils.plot_distribution_data(Y=data.test_labels, \n",
    "                                 dataset_name='y_test', \n",
    "                                 classes=data.classes, \n",
    "                                 fname='dist_test.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"dist_test.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ★サンプル画像の表示\n",
    "\n",
    "dltにはサンプル画像を表示するメソッドも用意されています。どういう画像が学習画像となっているかわかりますね。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlt.utils.plot_examples(data=data, \n",
    "                          num_examples=5, # 縦に何個表示するか (横はカテゴリーと一致)\n",
    "                         fname='fashion_mnist_examples.png' # ファイルパス\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fashion_mnist_examples.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 289s 5ms/step - loss: 0.6023 - acc: 0.7908 - val_loss: 0.3954 - val_acc: 0.8592\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 350s 6ms/step - loss: 0.3897 - acc: 0.8630 - val_loss: 0.3380 - val_acc: 0.8793\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.3415 - acc: 0.8805 - val_loss: 0.3063 - val_acc: 0.8903\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 306s 5ms/step - loss: 0.3150 - acc: 0.8892 - val_loss: 0.2884 - val_acc: 0.8974\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 310s 5ms/step - loss: 0.2922 - acc: 0.8971 - val_loss: 0.2751 - val_acc: 0.9004\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 308s 5ms/step - loss: 0.2746 - acc: 0.9029 - val_loss: 0.2673 - val_acc: 0.9040\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 299s 5ms/step - loss: 0.2603 - acc: 0.9070 - val_loss: 0.2538 - val_acc: 0.9093\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 296s 5ms/step - loss: 0.2494 - acc: 0.9118 - val_loss: 0.2533 - val_acc: 0.9070\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 308s 5ms/step - loss: 0.2372 - acc: 0.9168 - val_loss: 0.2441 - val_acc: 0.9105\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.2271 - acc: 0.9184 - val_loss: 0.2344 - val_acc: 0.9142\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 308s 5ms/step - loss: 0.2195 - acc: 0.9221 - val_loss: 0.2338 - val_acc: 0.9162\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 300s 5ms/step - loss: 0.2101 - acc: 0.9259 - val_loss: 0.2338 - val_acc: 0.9168\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape([-1, 28, 28, 1])\n",
    "X_test = X_test.reshape([-1, 28, 28, 1])\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "fit = model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=12,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.233760581553\n",
      "Test accuracy: 0.9168\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "★ 学習の経過を表す損失関数と精度のグラフは"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlt.utils.plot_loss_and_accuracy(fit,  #model.fitのインスタンス\n",
    "                                   fname='loss_and_accuracy_graph.png' #保存するファイル名とパス\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"loss_and_accuracy_graph.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "とすれば得られます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted probabilities for the test set\n",
    "preds = model.predict(X_test)\n",
    "cls = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ★テスト画像に対する分類精度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また分類タスクでは、各テスト画像に対してどの程度の精度で分類されたかを知りたいことが多いですね（というか知らないとだめです）。その時どう出力すればいいか迷うことがあるのですが、dltでは以下のようにすれば、わかりやすい結果が得られます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# とりあえず10枚\n",
    "for i in range(10):\n",
    "    dlt.utils.plot_prediction(\n",
    "        Yp=preds[i], # 各クラスに対して予測されたラベル \n",
    "        X=data.test_images[i], # 各クラスを表す画像\n",
    "        y=data.test_labels[i], # 正しいクラスのラベル\n",
    "        classes=data.classes, # ラベル名\n",
    "        top_n=False, # 上位いくつまで表示させるか. Falseならすべてのカテゴリーに対する精度を表示\n",
    "        fname='test-%i.png' % i) # 保存するファイル名"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"test-0.png\">\n",
    "<img src=\"test-1.png\">\n",
    "<img src=\"test-2.png\">\n",
    "<img src=\"test-3.png\">\n",
    "<img src=\"test-4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "オレンジ色の棒は正しいラベルの分類精度を表し、青色の棒は間違ったラベルの分類精度を表しています。\n",
    "\n",
    "最後の画像を例とすると、これは`Shirt`とほとんど90%以上の精度で分類していますが、5%程度で`T-shirt/top`と分類しています。\n",
    "\n",
    "結果を全体的に見たいときは、以下のConfusion Matrixが便利です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  ★Confusion Matrix\n",
    "\n",
    "confusion matrixについては以下のように出力できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlt.utils.plot_confusion_matrix(test_labels=data.test_labels, # 正しいテストラベル(one-hot vectorに変換する前)\n",
    "                                  y_pred=cls, # np.argmaxを通したYp \n",
    "                                  classes=data.classes, # クラス名\n",
    "                                  title='confusion matrix', # 出力グラフのタイトル\n",
    "                                  fname='confusion_matrix.png') # 出力パス"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"confusion_matrix.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "縦軸は正しいラベル、横軸は学習によって予測されたラベルを表しています。横軸から見れば、たとえば`Shirt`ラベルを見ると、67.80%で正しく`shirt`と分類されていますが、6.50%で`T-shirt/top`と分類されていることがわかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 宿題\n",
    "\n",
    "とりあえず、dltに触れるために簡単な宿題を出しておきます。これをこなせばありがたみがわかると思うので・・・\n",
    "\n",
    "1. MNISTデータセットの場合、上の手順に従えば、どのような結果が得られるでしょうか？（ネットワーク構造は変更しなくても構いません。)\n",
    "\n",
    "2. 出力画像の保存ディレクトリを変更してみましょう。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
